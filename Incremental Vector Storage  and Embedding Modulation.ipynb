{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04465a0",
   "metadata": {},
   "source": [
    "# Incremental Vector Storage  and Embedding Modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e740ce",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e6bf316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: langchain in /Users/apple/anaconda3/lib/python3.11/site-packages (0.0.292)\n",
      "Requirement already satisfied: faiss-cpu in /Users/apple/anaconda3/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: pypdf in /Users/apple/anaconda3/lib/python3.11/site-packages (3.16.0)\n",
      "Requirement already satisfied: GitPython in /Users/apple/anaconda3/lib/python3.11/site-packages (3.1.36)\n",
      "Requirement already satisfied: openpyxl in /Users/apple/anaconda3/lib/python3.11/site-packages (3.0.10)\n",
      "Requirement already satisfied: sentence-transformers in /Users/apple/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in /Users/apple/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: llama-cpp-python in /Users/apple/anaconda3/lib/python3.11/site-packages (0.2.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.37)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from GitPython) (4.0.10)\n",
      "Requirement already satisfied: et_xmlfile in /Users/apple/anaconda3/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in /Users/apple/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/apple/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (4.7.1)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/apple/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.0)\n",
      "Requirement already satisfied: fsspec in /Users/apple/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/apple/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/apple/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/apple/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /Users/apple/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/apple/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/apple/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: click in /Users/apple/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/apple/anaconda3/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/apple/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/apple/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain faiss-cpu pypdf GitPython openpyxl sentence-transformers transformers llama-cpp-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63cc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import (\n",
    "    LlamaCppEmbeddings, \n",
    "    HuggingFaceEmbeddings, \n",
    "    SentenceTransformerEmbeddings\n",
    ")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    DataFrameLoader,\n",
    "    GitLoader\n",
    "  )\n",
    "\n",
    "import pandas as pd\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5dfa4",
   "metadata": {},
   "source": [
    "## Text Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9b5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_splits(text_file):\n",
    "  \"\"\"Function takes in the text data and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  with open(text_file,'r') as txt:\n",
    "    data = txt.read()\n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = textSplit.split_text(data)\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672e401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa07a045",
   "metadata": {},
   "source": [
    "## Pdf Text Extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f257aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/Users/apple/Documents/TestingEmbbeding/9780723434177.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16db3c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15c4832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Objectives\\nIn this chapter you will learn to:\\n•Describe the anatomical position.\\n•Describe the anatomical planes.\\n•Deﬁne the anatomical terms used in anatomy and clinical practice.\\n•Describe the terms of movement, including those of the thumb.\\n•Understand the structure of bone.\\n•List the factors that contribute to joint stability.\\n•Describe the classiﬁcation of muscles according to their actions.\\n•Describe the organization and function of muscle.\\n•Draw a diagram of the components of a spinal nerve.\\n•Describe the layers of a blood vessel wall.\\n•Describe factors causing lymphatic ﬂuid movement and functions of lymph.\\n•Outline the layout of the gastrointestinal system and general functions.\\n•Outline the layout of the urinary system and general functions.Basic concepts of anatomy 1\\n3Such anatomical planes are frequently used in\\ncomputer tomography (CT) scans and magneticresonance imaging (MRI), to visualize muscle, bone,lung and other soft tissues as well as pathologies, forexample pancreatic cancer or a brain abscess.\\nTerms of position\\nThe terms of position commonly used in clinicalpractice and anatomy are illustrated in Figure 1.3.\\nTerms of movement\\nVarious terms are used to describe movements of thebody (Fig. 1.4):\\n•Flexion—forward movement in a sagittal\\nplane which in general reduces the angle atthe joint, e.g. bending the elbow. Exceptionsare at the ankle joint (when the angle isincreased) and the shoulder joint (when theangle between the upper limb and trunk isincreased).\\n•Extension—backward movement in a sagittal\\nplane which in general increases the angleat joints except at the ankle joint (whenthe angle is decreased) and the knee joint dueto lower limb rotation during embryonicdevelopment.DESCRIPTIVE ANATOMICAL\\nTERMS\\nThe anatomical position\\nThis is a standard position used in anatomy and\\nclinical medicine to allow accurate and consistentdescription of one body part in relation to another(Fig. 1.1):\\n•The head is directed forwards with eyes looking\\ninto the distance.\\n•The body is upright, legs together, and directed\\nforwards.\\n•The palms are turned forward, with the thumbs\\nlaterally.\\nAnatomical planes\\nThese comprise the following (Fig. 1.2):\\n•The median sagittal plane is the vertical plane\\npassing through the midline of the body fromthe front to the back. Any plane parallel to this istermed paramedian or sagittal.\\n•Coronal (or frontal) planes are vertical planes\\nperpendicular to the sagittal planes.\\n•Horizontal or transverse planes lie at right angles\\nto both the sagittal and coronal planes.Ch01-M3417.qxd  3/19/07  3:22 PM  Page 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b6fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pdf_splits(pdf_file):\n",
    "  \"\"\"Function takes in the pdf data and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  \n",
    "    \n",
    "  loader = PyPDFLoader(pdf_file)\n",
    "  pages = loader.load_and_split()  \n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=850,\n",
    "                                             chunk_overlap=200,\n",
    "                                             length_function=len)\n",
    "  doc_list = []\n",
    "  #Pages will be list of pages, so need to modify the loop\n",
    "  for pg in pages:\n",
    "    pg_splits = textSplit.split_text(pg.page_content)# here we are giveing each page content with is a text\n",
    "    doc_list.extend(pg_splits)\n",
    "\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b4ed8",
   "metadata": {},
   "source": [
    "## For Processing all PDF files in a directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6455036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def custom_text_splitter(text, chunk_size=850, chunk_overlap=200):\n",
    "    \"\"\"Custom text splitting function.\"\"\"\n",
    "    splits = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        splits.append(text[start:end])\n",
    "        start = end - chunk_overlap\n",
    "\n",
    "    return splits\n",
    "\n",
    "def get_pdf_splits_direc(directory):\n",
    "    \"\"\"Function takes in a directory containing PDF files and returns the splits\n",
    "    for further processing.\n",
    "\n",
    "    Args:\n",
    "    directory (str): Path to the directory containing PDF files.\n",
    "\n",
    "    Returns:\n",
    "    list: List of document splits.\n",
    "    \"\"\"\n",
    "    doc_list = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Load the PDF file\n",
    "            pdf_reader = PdfReader(file_path)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "\n",
    "            # Iterate through pages in the PDF\n",
    "            for page_num in range(num_pages):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                page_content = page.extract_text()\n",
    "\n",
    "                # Split the page content using custom splitter\n",
    "                page_splits = custom_text_splitter(page_content)\n",
    "                doc_list.extend(page_splits)\n",
    "\n",
    "    return doc_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d6219",
   "metadata": {},
   "source": [
    "## Excel Text Extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb6735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_excel_splits(excel_file,target_col,sheet_name):\n",
    "  trialDF = pd.read_excel(io=excel_file,\n",
    "                          engine='openpyxl',\n",
    "                          sheet_name=sheet_name)\n",
    "  \n",
    "  df_loader = DataFrameLoader(trialDF,\n",
    "                              page_content_column=target_col)\n",
    "  \n",
    "  excel_docs = df_loader.load()\n",
    "\n",
    "  return excel_docs\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218502a",
   "metadata": {},
   "source": [
    "## Coma Seperated Values Text Extraction Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd8a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_splits(csv_file):\n",
    "  \"\"\"Function takes in the csv and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  csvLoader = CSVLoader(csv_file)\n",
    "  csvdocs = csvLoader.load()\n",
    "  return csvdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfd69e",
   "metadata": {},
   "source": [
    "## IPYNB Text Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e90d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ipynb_splits(notebook):\n",
    "  \"\"\"Function takes the notebook file,reads the file \n",
    "  data as python script, then splits script data directly\"\"\"\n",
    "\n",
    "  with open(notebook) as fh:\n",
    "    nb = nbformat.reads(fh.read(), nbformat.NO_CONVERT)\n",
    "\n",
    "  exporter = PythonExporter()\n",
    "  source, meta = exporter.from_notebook_node(nb)\n",
    "\n",
    "  #Python file data is in the source variable\n",
    "  \n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = textSplit.split_text(source)\n",
    "  return doc_lis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752d639",
   "metadata": {},
   "source": [
    "## Git Hub File Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c12b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_files(repo_link, folder_path, file_ext):\n",
    "  # eg. loading only python files\n",
    "  git_loader = GitLoader(clone_url=repo_link,\n",
    "    repo_path=folder_path, \n",
    "    file_filter=lambda file_path: file_path.endswith(file_ext))\n",
    "  #Will take each file individual document\n",
    "  git_docs = git_loader.load()\n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = []\n",
    "  #Pages will be list of pages, so need to modify the loop\n",
    "  for code in git_docs:\n",
    "    code_splits = textSplit.split_text(code.page_content)\n",
    "    doc_list.extend(code_splits)\n",
    "\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946910d",
   "metadata": {},
   "source": [
    "## Incrementation of Exsisting Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7532b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_index(doc_list, embed_fn, index_store):\n",
    "  \"\"\"Function takes in existing vector_store, \n",
    "  new doc_list and embedding function that is \n",
    "  initialized on appropriate model. Local or online. \n",
    "  New embedding is merged with the existing index. If no \n",
    "  index given a new one is created\"\"\"\n",
    "  #check whether the doc_list is documents, or text\n",
    "  try:\n",
    "    faiss_db = FAISS.from_documents(doc_list, \n",
    "                              embed_fn)  \n",
    "  except Exception as e:\n",
    "    faiss_db = FAISS.from_texts(doc_list, \n",
    "                              embed_fn)\n",
    "  \n",
    "  if os.path.exists(index_store):\n",
    "    local_db = FAISS.load_local(index_store,embed_fn)\n",
    "    #merging the new embedding with the existing index store\n",
    "    local_db.merge_from(faiss_db)\n",
    "    print(\"Merge completed\")\n",
    "    local_db.save_local(index_store)\n",
    "    print(\"Updated index saved\")\n",
    "  else:\n",
    "    faiss_db.save_local(folder_path=index_store)\n",
    "    print(\"New store created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a367b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_docs_length(index_path, embed_fn):\n",
    "  test_index = FAISS.load_local(index_path,\n",
    "                              embeddings=embed_fn)\n",
    "  test_dict = test_index.docstore._dict\n",
    "  return len(test_dict.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8ef88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing out the above function with the open source \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "639fbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_pdf_splits(\"/Users/apple/Downloads/MBBS FirstYear/vishram-singh-textbook-of-clinical-neuroanatomy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69dcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BharatAI_documents = get_pdf_splits(\"/Users/apple/Desktop/Protoype/finalppt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "124bc742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BDC_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83321f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BharatAI_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a5adcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed\n",
      "Updated index saved\n"
     ]
    }
   ],
   "source": [
    "embed_index(doc_list=documents,embed_fn=embeddings,index_store='new_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84f5916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed\n",
      "Updated index saved\n"
     ]
    }
   ],
   "source": [
    "embed_index(doc_list=BharatAI_documents,embed_fn=embeddings,index_store='new_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8886c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18858"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_docs_length(index_path='new_index',embed_fn=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc745273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_index = FAISS.load_local(\"new_index\",embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddd3309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Nervous  System  I 165 \\n- Mononeuropathy:  Usually  one  neuron  is affected  and most \\ncommon  cause  is ischaemia  due  to pressure.  The  resultant \\ndysfunction  depends  on site and  degree  of injury. \\n• Bell's  palsy  is the compression  of a facial  nerve  in or just outside \\nstylomastoid  foramen  due to inflammation  and oedema  of the nerve. \\nThis causes  paralysis  of facial  muscles  and loss  of facial  expression \\non the affected  side  (Fig.  7.24). \\n• Acute  idiopathic  inflammatory  polyneuropathy  (Guillain-Barre \\nsyndrome)  is a sudden,  acute  and progressive  bilateral  ascending \\nparalysis  which  starts  at the lower  limb  and then  spreads  to arms, \\ntrunks  and  cranial  nerves.  It is characterized  by widespread \\ninflammation  with  some  demyelination  of spinal  and cranial  nerves \\nand the spinal  ganglia.\", metadata={}),\n",
       " Document(page_content=\"Nervous  System  I 165 \\n- Mononeuropathy:  Usually  one  neuron  is affected  and most \\ncommon  cause  is ischaemia  due  to pressure.  The  resultant \\ndysfunction  depends  on site and  degree  of injury. \\n• Bell's  palsy  is the compression  of a facial  nerve  in or just outside \\nstylomastoid  foramen  due to inflammation  and oedema  of the nerve. \\nThis causes  paralysis  of facial  muscles  and loss  of facial  expression \\non the affected  side  (Fig.  7.24). \\n• Acute  idiopathic  inflammatory  polyneuropathy  (Guillain-Barre \\nsyndrome)  is a sudden,  acute  and progressive  bilateral  ascending \\nparalysis  which  starts  at the lower  limb  and then  spreads  to arms, \\ntrunks  and  cranial  nerves.  It is characterized  by widespread \\ninflammation  with  some  demyelination  of spinal  and cranial  nerves \\nand the spinal  ganglia.\", metadata={}),\n",
       " Document(page_content='100 1 Handbook  of General  Anatomy \\n• Myocardial  ischaemia \\nPersistent  ischaemia  due to blockage  of more  than  one arteries  results \\nin necrosis  (death)  of the cardiac  muscle  (Fig.  4.19).  Pain,  not \\nrelieved  by rest,  gets  referred  to left arm,  chest,  and neigbhouring \\nareas. \\nFig. 4.19:  Myocardial  ischaemia', metadata={}),\n",
       " Document(page_content='100 1 Handbook  of General  Anatomy \\n• Myocardial  ischaemia \\nPersistent  ischaemia  due to blockage  of more  than  one arteries  results \\nin necrosis  (death)  of the cardiac  muscle  (Fig.  4.19).  Pain,  not \\nrelieved  by rest,  gets  referred  to left arm,  chest,  and neigbhouring \\nareas. \\nFig. 4.19:  Myocardial  ischaemia', metadata={})]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " result = test_index.similarity_search(\"what is myocartila infarction\")\n",
    " result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bf653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f3ef061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(query):\n",
    "    \"\"\"\n",
    "    Answer a question using the loaded model and preprocessed embeddings.\n",
    "    \"\"\"\n",
    "    # Search for documents similar to the query within the preprocessed embeddings\n",
    "    docs = test_index.similarity_search(query)\n",
    "\n",
    "    # Get the answer from the model\n",
    "    answer = loaded_chain.run(input_documents=docs, question=query)\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e7b388af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Myocardial infarction is a medical term for a heart attack. It is a condition in which one of the coronary arteries becomes blocked, preventing oxygen-rich blood from reaching the heart muscle. The lack of oxygen causes necrosis (death) of the cardiac muscle, leading to chest pain, not relieved by rest, referred to the left arm, chest, and neighbouring areas.\n"
     ]
    }
   ],
   "source": [
    "result = answer_question(\"what is myocartila infarction tell in detail\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b6f91b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb56250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3930b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
